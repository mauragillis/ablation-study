{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9307595,"sourceType":"datasetVersion","datasetId":5593457},{"sourceId":194303065,"sourceType":"kernelVersion"},{"sourceId":196859680,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Description\n\nYou can find the full winning solution [here](https://github.com/ilyanovo/isic-2024).\n\nThe below script is an ablation experiemnet in which only the images, no metadata, and no normalization are used. ","metadata":{}},{"cell_type":"code","source":"import os, cv2\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nfrom sklearn.utils import resample\n\nimport optuna\n\nfrom tqdm import tqdm\n\n\nimport os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\n\nimport h5py\nfrom PIL import Image\nfrom io import BytesIO\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-16T12:17:29.533383Z","iopub.execute_input":"2024-09-16T12:17:29.534182Z","iopub.status.idle":"2024-09-16T12:17:29.545173Z","shell.execute_reply.started":"2024-09-16T12:17:29.534147Z","shell.execute_reply":"2024-09-16T12:17:29.544323Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'target'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42\n\n\ncat_cols=[]\nnorm_cols=[]\nspecial_cols=[]\nfeature_cols=[]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:30.286681Z","iopub.execute_input":"2024-09-16T12:17:30.287046Z","iopub.status.idle":"2024-09-16T12:17:30.303079Z","shell.execute_reply.started":"2024-09-16T12:17:30.287016Z","shell.execute_reply":"2024-09-16T12:17:30.301965Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(test_path)\ntest_h5 = root / 'test-image.hdf5'\n\n# Set up device and random seed\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n\n# device = torch.device(\"cpu\")\n\nCONFIG = {\n    \"seed\": 42,\n    \"epochs\": 500,\n    \"img_size\": 336, #336,\n    \"model_name\": 'eva02_small_patch14_336.mim_in22k_ft_in1k',\n    \"train_batch_size\": 32,\n    \"valid_batch_size\": 64,\n    \"learning_rate\": 1e-4,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 2000,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"group_col\": 'patient_id',\n    \"device\": device\n}\n\ntransformations_base = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(\n            mean=[0.4815, 0.4578, 0.4082], \n            std=[0.2686, 0.2613, 0.2758], \n            max_pixel_value=255.0,\n            p=1.0\n        ),\n    ToTensorV2(),\n    ], p=1.)\n\ndef set_seed(random_seed):\n    random.seed(random_seed)\n    torch.manual_seed(random_seed)\n    np.random.seed(random_seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(random_seed)\n        torch.cuda.manual_seed_all(random_seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        \n        \nclass ISICModel(nn.Module):\n    def __init__(self, model_name, num_classes=1, drop_path_rate=0, drop_rate=0, pretrained=True, checkpoint_path=None):\n        super(ISICModel, self).__init__()\n        self.model = timm.create_model(\n            model_name, \n            pretrained=pretrained, \n            heckpoint_path=checkpoint_path,\n            drop_rate=drop_rate, \n            drop_path_rate=drop_path_rate)\n\n        in_features = self.model.head.in_features\n        self.model.head = nn.Linear(in_features, num_classes)\n        self.sigmoid = nn.Sigmoid() if num_classes == 1 else nn.Softmax()\n\n    def forward(self, images):\n        return self.sigmoid(self.model(images))\n    \n    \n    \nclass ISICDataset(Dataset):\n    def __init__(self, df, file_hdf, transforms=None):\n        self.df = df\n        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n        self.isic_ids = df['isic_id'].values\n        self.targets = df['target'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.isic_ids)\n    \n    def __getitem__(self, index):\n        isic_id = self.isic_ids[index]\n        img = np.array( Image.open(BytesIO(self.fp_hdf[isic_id][()])) )\n        target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'target': target,\n        }\n\n    \ndef prepare_loaders(df_train, h5_file, augmentations, CONFIG, num_workers=10):\n    \n    train_dataset = ISICDataset(df_train, h5_file, transforms=augmentations)\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=num_workers, shuffle=False, pin_memory=True, drop_last=False)\n    \n    return train_loader\n\n\n@torch.inference_mode()\ndef generate_predictions(model, dataloader, device):\n    model.eval()\n    \n\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    predictions_all = []\n    targets_all = []\n    for step, data in bar:        \n        images = data['image'].to(device, dtype=torch.float)\n        targets = data['target'].to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n\n        outputs = model(images).squeeze()\n\n        predictions_all.append(outputs.cpu().numpy())\n        targets_all.append(targets.cpu().numpy())\n    \n    gc.collect()\n\n    targets_all = np.concatenate(targets_all)\n    predictions_all = np.concatenate(predictions_all)\n    \n    return targets_all, predictions_all\n\n\nmodel = ISICModel(CONFIG['model_name'], pretrained=False, num_classes=3)\nmodel.load_state_dict( torch.load('../input/skin-models-base/ema_small_pretrained', weights_only=True) )\nmodel.to(CONFIG['device']);\n\ntest_df[\"path\"] = '../input/isic-2024-challenge/test-image/image/' + test_df['isic_id'] + \".jpg\"\ntest_df['target'] = 0\ndata_loader_test = prepare_loaders(test_df, test_h5, transformations_base, CONFIG, num_workers=2)\n\ntargets_all, predictions_all = generate_predictions(model, data_loader_test, device)\n\ntest_df['old_set_0'] = predictions_all[:, 0]\ntest_df['old_set_1'] = predictions_all[:, 1]\ntest_df['old_set_2'] = predictions_all[:, 2]\n\ntest_df[['isic_id', 'old_set_0', 'old_set_1', 'old_set_2']].to_parquet(\n    'old_data_model_forecast__test.parquet')\nmodel.to('cpu');","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:30.547085Z","iopub.execute_input":"2024-09-16T12:17:30.547466Z","iopub.status.idle":"2024-09-16T12:17:33.675276Z","shell.execute_reply.started":"2024-09-16T12:17:30.547435Z","shell.execute_reply":"2024-09-16T12:17:33.674323Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(test_path)\n\ntest_df[\"path\"] = '../input/isic-2024-challenge/test-image/image/' + test_df['isic_id'] + \".jpg\"\ntest_df['target'] = 0\ndata_loader_test = prepare_loaders(test_df, test_h5, transformations_base, CONFIG, num_workers=2)\n\n\nbase_model_path = \"../input/skin-models-base\"\nfor base_model_index in range(5):\n    base_model_full_path = os.path.join(base_model_path, f\"eva_model__{base_model_index}\")\n    \n    model = ISICModel(CONFIG['model_name'], pretrained=False, num_classes=1)\n    model.load_state_dict(torch.load(base_model_full_path, weights_only=True))\n    model.to(CONFIG['device']);\n    targets_all, predictions_all = generate_predictions(model, data_loader_test, device)\n    test_df[f\"predictions__{base_model_index}\"] = predictions_all\n    model.to('cpu');\n    \ntest_df = test_df[\n    ['isic_id', 'patient_id',\n         'predictions__0', 'predictions__1', 'predictions__2', 'predictions__3', 'predictions__4']\n].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:33.677337Z","iopub.execute_input":"2024-09-16T12:17:33.678041Z","iopub.status.idle":"2024-09-16T12:17:42.740167Z","shell.execute_reply.started":"2024-09-16T12:17:33.678006Z","shell.execute_reply":"2024-09-16T12:17:42.739316Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oof_forecasts_eva = pd.read_parquet('../input/skin-models-base/oof_forecasts_eva.parquet')\noof_forecasts_eva_agg = oof_forecasts_eva.groupby('fold_n').agg(**{\n        \"mean_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"mean\"),\n        \"std_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"std\")})\n\n#Scaling works better on both public and private leaderboards when it is done using values from just one fold\nfor i in range(5):\n    test_df[f'predictions__{i}'] = (\n        test_df[f'predictions__{i}'] - oof_forecasts_eva_agg.loc[0].mean_preds\n    ) / oof_forecasts_eva_agg.loc[0].std_preds\n    \ntest_df[\"predictions_eva\"] = test_df[[f'predictions__{i}' for i in range(5)]].mean(axis=1)\ntest_df_eva = test_df.copy()\n\n\n# tmp_predictions_all_rank_pr\noof_forecasts_eva = oof_forecasts_eva[['isic_id', 'patient_id', 'tmp_predictions_all__pr']].rename(columns={\n    'tmp_predictions_all__pr': 'predictions_eva'\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:42.752194Z","iopub.execute_input":"2024-09-16T12:17:42.752578Z","iopub.status.idle":"2024-09-16T12:17:44.660509Z","shell.execute_reply.started":"2024-09-16T12:17:42.752545Z","shell.execute_reply":"2024-09-16T12:17:44.659696Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ISICModelEdgnet(nn.Module):\n    def __init__(self, model_name, num_classes=1, pretrained=True, checkpoint_path=None, *args, **kwargs):\n        super(ISICModelEdgnet, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes, global_pool='avg')\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, images):\n        return self.sigmoid(self.model(images))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:44.661637Z","iopub.execute_input":"2024-09-16T12:17:44.661922Z","iopub.status.idle":"2024-09-16T12:17:44.668328Z","shell.execute_reply.started":"2024-09-16T12:17:44.661899Z","shell.execute_reply":"2024-09-16T12:17:44.667332Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ISICModelEdgnet(nn.Module):\n    def __init__(self, model_name, num_classes=1, pretrained=True, checkpoint_path=None, *args, **kwargs):\n        super(ISICModelEdgnet, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes, global_pool='avg')\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, images):\n        return self.sigmoid(self.model(images))\n    \n\nCONFIG = {\n    \"seed\": 42,\n    \"epochs\": 500,\n    \"img_size\": 256, #336,\n#     \"model_name\": 'eva02_small_patch14_336.mim_in22k_ft_in1k',\n    \"train_batch_size\": 32,\n    \"valid_batch_size\": 64,\n    \"learning_rate\": 1e-4,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 2000,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"group_col\": 'patient_id',\n    \"device\": device\n}\n\ntransformations_base = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(\n            mean=[0.4815, 0.4578, 0.4082], \n            std=[0.2686, 0.2613, 0.2758], \n            max_pixel_value=255.0,\n            p=1.0\n        ),\n    ToTensorV2(),\n    ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:44.669523Z","iopub.execute_input":"2024-09-16T12:17:44.669847Z","iopub.status.idle":"2024-09-16T12:17:44.680135Z","shell.execute_reply.started":"2024-09-16T12:17:44.669818Z","shell.execute_reply":"2024-09-16T12:17:44.679315Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(test_path)\n\ntest_df[\"path\"] = '../input/isic-2024-challenge/test-image/image/' + test_df['isic_id'] + \".jpg\"\ntest_df['target'] = 0\ndata_loader_test = prepare_loaders(test_df, test_h5, transformations_base, CONFIG, num_workers=2)\n\n\nbase_model_path = \"../input/skin-models-base\"\nfor base_model_index in range(5):\n    base_model_full_path = os.path.join(base_model_path, f\"edg_model__{base_model_index}\")\n    \n    model = ISICModelEdgnet('edgenext_base.in21k_ft_in1k', pretrained=False, num_classes=1)\n    model.load_state_dict(torch.load(base_model_full_path, weights_only=True))\n    model.to(CONFIG['device']);\n    targets_all, predictions_all = generate_predictions(model, data_loader_test, device)\n    test_df[f\"predictions__{base_model_index}\"] = predictions_all\n    model.to('cpu');\n    \noof_forecasts_edgenext = pd.read_parquet('../input/skin-models-base/oof_forecasts_edgenext_base.parquet')\noof_forecasts_edgenext_agg = oof_forecasts_edgenext.groupby('fold_n').agg(**{\n        \"mean_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"mean\"),\n        \"std_preds\": pd.NamedAgg(\"tmp_predictions_all\", \"std\")})\n\n#Scaling works better on both public and private leaderboards when it is done using values from just one fold\nfor i in range(5):\n    test_df[f'predictions__{i}'] = (\n        test_df[f'predictions__{i}'] - oof_forecasts_edgenext_agg.loc[0].mean_preds\n    ) / oof_forecasts_edgenext_agg.loc[0].std_preds\n    \ntest_df[\"predictions_edg\"] = test_df[[f'predictions__{i}' for i in range(5)]].mean(axis=1)\ntest_df = test_df[['isic_id', 'patient_id', 'predictions_edg']].reset_index(drop=True)\ntest_df_edg = test_df.copy()\n\n\noof_forecasts_edgenext = oof_forecasts_edgenext[['isic_id', 'patient_id', 'tmp_predictions_all__pr']].rename(columns={\n    'tmp_predictions_all__pr': 'predictions_edg'\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:44.681542Z","iopub.execute_input":"2024-09-16T12:17:44.68187Z","iopub.status.idle":"2024-09-16T12:17:55.159526Z","shell.execute_reply.started":"2024-09-16T12:17:44.681845Z","shell.execute_reply":"2024-09-16T12:17:55.158609Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:55.212025Z","iopub.execute_input":"2024-09-16T12:17:55.212349Z","iopub.status.idle":"2024-09-16T12:17:55.221679Z","shell.execute_reply.started":"2024-09-16T12:17:55.21232Z","shell.execute_reply":"2024-09-16T12:17:55.220938Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Read & Feature Engineering","metadata":{}},{"cell_type":"code","source":"# '../input/old-models-predictions/old_data_model_forecast.parquet'\ndef add_old_model_preds(df_train, path):\n    old_data_model_preds = pd.read_parquet(path) #old_data_model_forecast\n    feature_cols_new = []\n    df_train = df_train.merge(old_data_model_preds, how=\"left\", on=[\"isic_id\"])\n    feature_cols_new += [i for i in old_data_model_preds.columns if i!='isic_id']\n    return df_train, feature_cols_new","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:55.222698Z","iopub.execute_input":"2024-09-16T12:17:55.222968Z","iopub.status.idle":"2024-09-16T12:17:55.2311Z","shell.execute_reply.started":"2024-09-16T12:17:55.222946Z","shell.execute_reply":"2024-09-16T12:17:55.230382Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\ndf_subm = pd.read_csv(subm_path, index_col=id_col)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:17:55.232238Z","iopub.execute_input":"2024-09-16T12:17:55.232661Z","iopub.status.idle":"2024-09-16T12:18:01.887519Z","shell.execute_reply.started":"2024-09-16T12:17:55.232631Z","shell.execute_reply":"2024-09-16T12:18:01.886662Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in feature_cols: \n    df_test[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n    \ncat_columns = list(df_test.select_dtypes('category').columns)\nfor col in feature_cols[76:77]:\n    if col not in cat_columns:\n        if df_test[col].isna().mean() != 1:\n            filler = df_test[col].median()\n        else:\n            filler = 0\n        df_test[col] = df_test[col].fillna(filler)\n    else:\n        vc = df_test[col].value_counts()\n        if vc.shape[0] == 0:\n            filler = 0\n        else:\n            filler = vc.index[0]\n    \n        df_test[col] = df_test[col].fillna(filler)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:18:34.814855Z","iopub.execute_input":"2024-09-16T12:18:34.815229Z","iopub.status.idle":"2024-09-16T12:18:34.952074Z","shell.execute_reply.started":"2024-09-16T12:18:34.8152Z","shell.execute_reply":"2024-09-16T12:18:34.950932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:18:35.222189Z","iopub.execute_input":"2024-09-16T12:18:35.222814Z","iopub.status.idle":"2024-09-16T12:18:35.228105Z","shell.execute_reply.started":"2024-09-16T12:18:35.22278Z","shell.execute_reply":"2024-09-16T12:18:35.227168Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train, extra_f = add_old_model_preds(df_train, '../input/old-models-predictions/old_data_model_forecast.parquet')\ndf_test, extra_f = add_old_model_preds(df_test, 'old_data_model_forecast__test.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:21:36.865581Z","iopub.execute_input":"2024-09-16T12:21:36.866032Z","iopub.status.idle":"2024-09-16T12:21:38.513932Z","shell.execute_reply.started":"2024-09-16T12:21:36.865998Z","shell.execute_reply":"2024-09-16T12:21:38.513064Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = df_train.merge(oof_forecasts_eva, how=\"left\", on='isic_id')\ndf_test = df_test.merge(test_df_eva, how=\"left\", on='isic_id')\n\nfiltered_extra_f = [f for f in extra_f if not f.endswith('_m')]\nfeature_cols += filtered_extra_f\n\nfeature_cols += ['predictions_eva']","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:23:06.377566Z","iopub.execute_input":"2024-09-16T12:23:06.377944Z","iopub.status.idle":"2024-09-16T12:23:07.076026Z","shell.execute_reply.started":"2024-09-16T12:23:06.377918Z","shell.execute_reply":"2024-09-16T12:23:07.075053Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = df_train.merge(oof_forecasts_edgenext, how=\"left\", on='isic_id')\ndf_test = df_test.merge(test_df_edg, how=\"left\", on='isic_id')\n\nfeature_cols += ['predictions_edg']","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:23:07.077838Z","iopub.execute_input":"2024-09-16T12:23:07.0782Z","iopub.status.idle":"2024-09-16T12:23:08.303032Z","shell.execute_reply.started":"2024-09-16T12:23:07.078169Z","shell.execute_reply":"2024-09-16T12:23:08.30211Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Optuna HyperParam Tuned Models","metadata":{}},{"cell_type":"code","source":"lgb_params = {\n    'objective':        'binary',\n    'verbosity':        -1,\n    'n_iter':           200,\n    'boosting_type':    'gbdt',\n    \"device\" : \"gpu\",\n    'random_state':     seed,\n    'lambda_l1':        0.08758718919397321, \n    'lambda_l2':        0.0039689175176025465, \n    'learning_rate':    0.03231007103195577, \n    'max_depth':        4, \n    'num_leaves':       103, \n    'colsample_bytree': 0.8329551585827726, \n    'colsample_bynode': 0.4025961355653304, \n    'bagging_fraction': 0.7738954452473223, \n    'bagging_freq':     4, \n    'min_data_in_leaf': 85, \n    'scale_pos_weight': 2.7984184778875543,\n}\n\ncb_params = {\n    'loss_function':     'Logloss',\n    'iterations':        200,\n    'verbose':           False,\n    'random_state':      seed,\n    'max_depth':         7, \n    'learning_rate':     0.06936242010150652, \n    'scale_pos_weight':  2.6149345838209532, \n    'l2_leaf_reg':       6.216113851699493, \n    'subsample':         0.6249261779711819, \n    'min_data_in_leaf':  24,\n    'cat_features':      cat_cols,\n}\n\nxgb_params  = {\n    'enable_categorical': True,\n    'tree_method':        'hist',\n    'random_state':       seed,\n    'learning_rate':      0.08501257473292347, \n    'lambda':             8.879624125465703, \n    'alpha':              0.6779926606782505, \n    'max_depth':          6, \n    'subsample':          0.6012681388711075, \n    'colsample_bytree':   0.8437772277074493, \n    'colsample_bylevel':  0.5476090898823716, \n    'colsample_bynode':   0.9928601203635129, \n    'scale_pos_weight':   3.29440313334688,\n    \"device\": \"cuda\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:23:09.244379Z","iopub.execute_input":"2024-09-16T12:23:09.245114Z","iopub.status.idle":"2024-09-16T12:23:09.255375Z","shell.execute_reply.started":"2024-09-16T12:23:09.245083Z","shell.execute_reply":"2024-09-16T12:23:09.254422Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Cross Validation","metadata":{}},{"cell_type":"code","source":"def custom_metric_raw(y_hat, y_true):\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc\n\n\ndef custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    partial_auc = custom_metric_raw(y_hat, y_true)\n    return partial_auc\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:23:09.740849Z","iopub.execute_input":"2024-09-16T12:23:09.74149Z","iopub.status.idle":"2024-09-16T12:23:09.748594Z","shell.execute_reply.started":"2024-09-16T12:23:09.741457Z","shell.execute_reply":"2024-09-16T12:23:09.747509Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pydantic import BaseModel\n\nclass ModelConfigCB(BaseModel):\n    iterations: int = 1000\n    learning_rate: float = 0.06936242010150652\n    l2_leaf_reg: float = 6.216113851699493\n    loss_function: str = \"Logloss\"\n    bagging_temperature: float = 1\n    random_seed: int = seed\n    border_count: int = 128\n    grow_policy: str = \"SymmetricTree\" #Depthwise Lossguide\n    min_data_in_leaf: int = 24\n    depth: int  = 7\n    do_sample: bool = True","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:23:09.955939Z","iopub.execute_input":"2024-09-16T12:23:09.956612Z","iopub.status.idle":"2024-09-16T12:23:10.181449Z","shell.execute_reply.started":"2024-09-16T12:23:09.956581Z","shell.execute_reply":"2024-09-16T12:23:10.180607Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_model_old_cb(cb_params, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    metric_list = []\n    models = []\n    for random_seed in range(1, 10):\n        tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n        metrics_ev_df = []\n        test_forecast = []\n        val_forecast = []\n        for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n            train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            \n            for col in ['predictions_edg', 'predictions_eva']:\n                train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n            train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n            val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n        \n            cb_model = Pipeline([\n                ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n                ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=seed)),\n                ('classifier', cb.CatBoostClassifier(**cb_params)),\n            ])\n            \n            cb_model.fit(train_slice_x, train_slice_y)\n            preds_cb = cb_model.predict_proba(val_slice_x)[:, 1]\n            metric = custom_metric_raw(preds_cb, val_slice_y.values)\n            metric_list.append(metric)\n            models.append(cb_model)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models\n    \n    \ndef run_model_old_lgb(lgb_params, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    metric_list = []\n    models = []\n    for random_seed in range(1, 10):\n        random_seed = random_seed * 10 + 17\n        tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n        metrics_ev_df = []\n        test_forecast = []\n        val_forecast = []\n        for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n            train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            \n            for col in ['predictions_edg','predictions_eva']:\n                train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n            train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n            val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n        \n            cb_model = Pipeline([\n                ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=random_seed)),\n                ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=random_seed)),\n                ('classifier', lgb.LGBMClassifier(**lgb_params)),\n            ])\n            \n            cb_model.fit(train_slice_x, train_slice_y)\n            preds_cb = cb_model.predict_proba(val_slice_x)[:, 1]\n            metric = custom_metric_raw(preds_cb, val_slice_y.values)\n            metric_list.append(metric)\n            models.append(cb_model)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models\n    \n    \ndef run_model_old_xgb(xgb_params, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    metric_list = []\n    models = []\n    for random_seed in range(1, 10):\n        random_seed = random_seed * 10 + 88\n        tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n        metrics_ev_df = []\n        test_forecast = []\n        val_forecast = []\n        for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n            train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n            \n            for col in ['predictions_edg','predictions_eva']:\n                train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n                \n            train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n            val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n        \n            cb_model = Pipeline([\n                ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=random_seed)),\n                ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=random_seed)),\n                ('classifier', xgb.XGBClassifier(**xgb_params)),\n            ])\n            \n            cb_model.fit(train_slice_x, train_slice_y)\n            preds_cb = cb_model.predict_proba(val_slice_x)[:, 1]\n            metric = custom_metric_raw(preds_cb, val_slice_y.values)\n            metric_list.append(metric)\n            models.append(cb_model)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models\n    \n    \ndef run_model_cb(trial , test=False, reduce=True, columns_to_drop=None) -> float:\n    columns_to_drop = [] if columns_to_drop is None else columns_to_drop\n    model_config_cb = ModelConfigCB(\n        iterations = 2000,\n        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.08) if not test else trial.get('learning_rate'),\n        l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1, 20) if not test else trial.get('l2_leaf_reg'),\n        random_strength = trial.suggest_float('random_strength', 0, 5) if not test else trial.get('random_strength'),\n        loss_function = \"Logloss\",\n        depth = trial.suggest_int('depth', 2, 8) if not test else trial.get('depth'),\n        bagging_temperature = trial.suggest_float('bagging_temperature', 0, 10) if not test else trial.get('bagging_temperature'),\n        border_count = trial.suggest_categorical('border_count', [128, 256]) if not test else trial.get('border_count'),\n        grow_policy = trial.suggest_categorical('grow_policy', [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]) if not test else trial.get('grow_policy'),\n        random_seed=42,\n        min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 8, 40) if not test else trial.get('min_data_in_leaf'),\n    )\n    \n    models = []\n    metric_list = []\n    \n    with tqdm() as pbar:\n        for random_seed in range(1, 10):\n            tsp = StratifiedGroupKFold(5, shuffle=True, random_state=random_seed)\n            metrics_ev_df = []\n            test_forecast = []\n            val_forecast = []\n            for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[group_col])):\n                train_slice_x = df_train.iloc[train_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n                val_slice_x = df_train.iloc[val_index][[i for i in feature_cols if i not in columns_to_drop]].reset_index(drop=True)\n\n                train_slice_y = df_train.iloc[train_index]['target'].reset_index(drop=True)\n                val_slice_y = df_train.iloc[val_index]['target'].reset_index(drop=True)\n                \n                if model_config_cb.do_sample:\n                    cb_model = Pipeline([\n                        ('sampler_1', RandomOverSampler(sampling_strategy=0.003 , random_state=random_seed)),\n                        ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=random_seed)),\n                    ])\n\n                    train_slice_x, train_slice_y = cb_model.fit_resample(train_slice_x, train_slice_y)\n                \n                for col in ['predictions_edg', 'predictions_eva']:\n                    train_slice_x[col] = train_slice_x[col] + np.random.normal(loc=0, scale=0.1, size=train_slice_x.shape[0])\n                \n                \n                \n                clf_catboost = cb.CatBoostClassifier(\n                    loss_function=model_config_cb.loss_function,\n                    eval_metric='AUC',\n                    task_type='GPU',\n                    learning_rate=model_config_cb.learning_rate,\n                    od_wait=100,\n                    random_state=random_seed,\n                    depth=model_config_cb.depth,\n                    l2_leaf_reg=model_config_cb.l2_leaf_reg,\n                    min_data_in_leaf=model_config_cb.min_data_in_leaf,\n                    bagging_temperature=model_config_cb.bagging_temperature,\n                    border_count=model_config_cb.border_count,\n                    grow_policy=model_config_cb.grow_policy, \n                    devices='0',\n                    iterations=model_config_cb.iterations,\n                )\n\n                train_pool = cb.Pool(train_slice_x, train_slice_y.values, cat_features=cat_cols) \n                val_pool = cb.Pool(val_slice_x, val_slice_y.values, cat_features=cat_cols) \n\n                clf_catboost.fit(train_pool, eval_set=val_pool,verbose=False)\n                preds_cb = clf_catboost.predict_proba(val_slice_x)[:, 1]\n                metric = custom_metric_raw(preds_cb, val_slice_y.values)\n                metric_list.append(metric)\n                models.append(clf_catboost)\n                pbar.update(1)\n\n    if reduce:\n        return np.mean(metric_list), models\n    else:\n        return metric_list, models","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:23:10.183264Z","iopub.execute_input":"2024-09-16T12:23:10.183631Z","iopub.status.idle":"2024-09-16T12:23:10.229379Z","shell.execute_reply.started":"2024-09-16T12:23:10.183605Z","shell.execute_reply":"2024-09-16T12:23:10.228423Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns_to_drop=[]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_config_cb = ModelConfigCB(**{\n     'learning_rate': 0.02606161517843435,\n     'l2_leaf_reg': 18.04422276698195,\n     'random_strength': 4.7069580783889995,\n     'depth': 6,\n     'bagging_temperature': 0.8735940473548339,\n     'border_count': 256,\n     'grow_policy': 'Lossguide',\n     'min_data_in_leaf': 38})\n\nmetric_list, models_cb = run_model_cb(\n    model_config_cb.dict(), test=True, reduce=False, columns_to_drop=columns_to_drop)\n\nprint(np.mean(metric_list))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T12:23:10.6518Z","iopub.execute_input":"2024-09-16T12:23:10.652489Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metric_list, models_lgb = run_model_old_lgb(\n    lgb_params, reduce=False, columns_to_drop=columns_to_drop)\n\nprint(np.mean(metric_list))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metric_list, models_xgb = run_model_old_xgb(\n    xgb_params, reduce=False, columns_to_drop=columns_to_drop)\n\nprint(np.mean(metric_list))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"for col in feature_cols: \n    df_test[col].replace([np.inf, -np.inf], np.nan, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T09:12:30.327959Z","iopub.execute_input":"2024-08-20T09:12:30.328804Z","iopub.status.idle":"2024-08-20T09:12:30.45471Z","shell.execute_reply.started":"2024-08-20T09:12:30.328774Z","shell.execute_reply":"2024-08-20T09:12:30.453732Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model_predictions(models_list, df_test, feature_cols, columns_to_drop):\n    df_test_size = int(df_test.shape[0] // 2)\n    predictions_tmp = None\n    for model in models_list:\n        preds_tmp = model.predict_proba(\n                df_test[[i for i in feature_cols if i not in columns_to_drop]])[:, 1]\n\n        preds_tmp = pd.DataFrame({\"preds\": preds_tmp})\n        preds_tmp = preds_tmp['preds'].rank(pct=True)\n\n        if predictions_tmp is None:\n            predictions_tmp = preds_tmp.values\n        else:\n            predictions_tmp += preds_tmp.values\n\n    predictions_tmp = predictions_tmp / len(models_list)\n    return predictions_tmp","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_cb = get_model_predictions(models_cb, df_test, feature_cols, columns_to_drop)\npredictions_xgb = get_model_predictions(models_xgb, df_test, feature_cols, columns_to_drop)\npredictions_lgb = get_model_predictions(models_lgb, df_test, feature_cols, columns_to_drop)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = (\n    predictions_lgb +\n    predictions_cb +\n    predictions_xgb\n) / 3\n\ndf_subm['target'] = predictions\n\n\ndf_subm.to_csv('submission.csv')\ndf_subm.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T09:21:31.875452Z","iopub.execute_input":"2024-08-20T09:21:31.876283Z","iopub.status.idle":"2024-08-20T09:21:31.880423Z","shell.execute_reply.started":"2024-08-20T09:21:31.876251Z","shell.execute_reply":"2024-08-20T09:21:31.879369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:14:08.094161Z","iopub.execute_input":"2024-08-18T17:14:08.094553Z","iopub.status.idle":"2024-08-18T17:14:12.227334Z","shell.execute_reply.started":"2024-08-18T17:14:08.094526Z","shell.execute_reply":"2024-08-18T17:14:12.22631Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}